---
title: "Song songdata"
author: "Silvia Ventoruzzo"
date: "10/5/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preparation

Packages & functions
```{r}
library(tidyverse)
library(tidytext)
library(DataExplorer)
library(gridExtra)
library(grid)
library(tm)
library(topicmodels)
library(gtools)
library(gtable)
library(quanteda)
library(stopwords)
library(reshape2)
library(ldatuning)
library(cld3)
```

Load dataset
```{r}
songs_genre <- read_csv("./Data/lyrics.csv.zip")
songs       <- read_csv("./Data/songdata.csv.zip")
```

Join datasets
```{r}
# Clean before joining
songs_genre <- songs_genre %>%
  dplyr::select(-index, -lyrics) %>%
  mutate(song   = gsub("-", " ", song),
         artist = gsub("-", " ", artist),
         artist = ifelse(artist == "beyonce knowles", "beyonce", artist)) %>%
  filter(genre != "Not Available") %>%
  mutate_if(is.character, tolower)

songs <- songs %>%
  dplyr::select(-link) %>%
  filter(!is.na(text)) %>%
  mutate_if(!(grepl("text", names(.))), tolower)

# Join
songdata <- songs %>%
  inner_join(songs_genre, by = c("artist", "song"))

rm("songs_genre", "songs")
```

We would like to keep only 200 songs, but at the moment we have 11555. We initially look at the language, restricting our dataset of only songs in English, and length of the song, keeping only songs with length bigger than 1st quantile.
```{r}
# Language
songdata <- songdata %>%
  mutate(text_language = detect_language(text))

songdata %>%
  count(text_language) %>%
  mutate(text_language = reorder(text_language, -n)) %>%
  ggplot() +
  geom_bar(aes(x = text_language, y = n), stat = "identity")

songdata <- songdata %>%
  filter(text_language == "en") %>%
  dplyr::select(-text_language)

# Length
songdata <- songdata %>%
  mutate(text_length = str_length(songdata$text))

songdata %>%
  ggplot() +
  geom_boxplot(aes(x = factor(0), y = text_length)) +
  coord_flip()

songdata <- songdata %>%
  filter(text_length > quantile(text_length, 0.25)) %>%
  dplyr::select(-text_length)
```

We now look at the distributions of the variables artist, year and genre.
```{r}
# Year
songdata %>%
  count(year) %>%
  mutate(occurences = n/sum(n)) %>%
  ggplot() +
  geom_bar(aes(x = year, y = occurences), stat = "identity") +
  scale_x_continuous(breaks = seq(min(songdata$year), max(songdata$year), 5)) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title    = "Distribution of song years",
       subtitle = "Initial data")

# Genre
songdata %>%
  count(genre) %>%
  mutate(occurences = n/sum(n)) %>%
  ggplot() +
  geom_bar(aes(x = reorder(genre, -occurences), y = occurences), stat = "identity") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x        = "genre",
       title    = "Distribution of music genres",
       subtitle = "Initial data")

# Artist
songdata %>%
  count(artist) %>%
  mutate(occurences = n/sum(n)) %>%
  ggplot() +
  geom_bar(aes(x = reorder(artist, occurences), y = occurences), stat = "identity") +
  scale_y_continuous(labels = scales::percent_format()) +
  coord_flip() +
  labs(x        = "artist",
       title    = "Distribution of artists",
       subtitle = "Initial data")
```

We can see that great part of the songs are from 2005 onwards. We will therefore firstly restrict the dataset to the songs from 2010. We will furthermore only keep songs of the 5 most common music genres (pop, rock, hip-hop, jazz, country).
```{r}
songdata <- songdata %>%
  filter(year >= 2010,
         genre %in% c("pop", "rock", "hip-hop", "jazz", "country"))
```

We still have too many songs (1483). We will thus now look at artists. We wish to create some variability in the texts, therefore it would be good to have a mixture of different artists. I would however prefer having famous artists, to make the project more relatable, but also considering a mix of genres. Following artists will be kept:
- adele
- aerosmith
- avril lavigne
- backstreet boys
- billie holiday
- bon jovi
- coldplay
- depeche mode
- dolly parton
- drake
- ed sheeran
- ella fitzgerald
- eminem
- enrique iglesias
- evanescence
- foo fighters
- fall out boy
- george jones
```{r}
set.seed(62781649)
songdata <- songdata %>%
  filter(artist %in% c("adele", "aerosmith", "avril lavigne", "backstreet boys", "billie holiday", "bon jovi", "coldplay", "depeche mode", "dolly parton", "drake", "ed sheeran", "ella fitzgerald", "eminem", "evanescence", "foo fighters", "fall out boy", "george jones")) %>%
  sample_n(200)
```

Produce now final plots
```{r}
distribution_plots <- list()
distribution_plots[["artist"]] <- songdata %>%
  count(artist) %>%
  mutate(occurences = n/sum(n)) %>%
  ggplot() +
  geom_bar(aes(x = reorder(artist, occurences), y = occurences), stat = "identity", fill = "chartreuse4") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(axis.title.y = element_text(size = 12),
        axis.text.y  = element_text(size = 7),
        axis.title.x = element_blank()) +
  labs(x = "artist") +
  coord_flip()
distribution_plots[["genre"]] <- songdata %>%
  count(genre) %>%
  mutate(occurences = n/sum(n)) %>%
  ggplot() +
  geom_bar(aes(x = reorder(genre, occurences), y = occurences), stat = "identity", fill = "chartreuse4") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(axis.title.y = element_text(size = 12),
        axis.title.x = element_blank()) +
  labs(x = "genre") +
  coord_flip()
distribution_plots[["year"]] <- songdata %>%
  count(year) %>%
  mutate(occurences = n/sum(n)) %>%
  ggplot() +
  geom_bar(aes(x = year, y = occurences), stat = "identity", fill = "chartreuse4") +
  scale_x_continuous(breaks = seq(min(songdata$year), max(songdata$year), 1),
                     trans  = "reverse") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(axis.title.y = element_text(size = 12),
        axis.title.x = element_blank()) +
  coord_flip()
#grid.newpage()
grid.draw(rbind(ggplotGrob(distribution_plots[["artist"]]), ggplotGrob(distribution_plots[["genre"]]), ggplotGrob(distribution_plots[["year"]]), size = "first"))
rm(distribution_plots)
```

Look at summed percentages
```{r}
# Artist
songdata %>%
  count(artist) %>%
  arrange(-n) %>%
  mutate(perc = n/sum(n), 
         cumsum = cumsum(perc))

# Genre
songdata %>%
  count(genre) %>%
  arrange(n) %>%
  mutate(perc = n/sum(n), 
         cumsum = cumsum(perc))
```

Combination artist-genre
Each artist is associated to only one genre
```{r}
songdata %>%
  count(artist, genre) %>%
  count(artist)
```

Text length
```{r}
songdata %>%
  mutate(text_length = str_length(songdata$text)) %>%
  ggplot() +
  geom_boxplot(aes(x = factor(0), y = text_length), fill = "chartreuse4") +
  theme(axis.title.y = element_blank(),
        axis.text.y  = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12)) +
  labs(y = "text length") +      
  coord_flip() +
  facet_wrap(~genre)

```

text
```{r}
# songdata <- songdata %>%
#   mutate(text = tolower(text),
#          text = removePunctuation(text),
#          text = removeNumbers(text),
#          text = stripWhitespace(text),
#          text = stemDocument(text))
```

genre - year
```{r}
songdata %>%
  count(year, genre) %>%
  group_by(year) %>%
  mutate(percentage = n/sum(n)) %>%
  ungroup() %>%
  ggplot() +
  geom_line(aes(x = year, y = percentage, color = genre))

# # From: https://towardsdatascience.com/text-analytics-topic-modelling-on-music-genres-song-songdata-deb82c86caa2
# songdata %>% 
#   mutate(fiveyears = as.character(year) %>%
#                       paste("01", "01", sep = "-") %>%
#                       as.Date() %>%
#                       lubridate::floor_date("y year")) %>%
#   count(fiveyears, genre) %>% 
#   group_by(fiveyears) %>%
#   mutate(freq = round(n/sum(n), 2)) %>% 
#   # filter(genre %in% c("Country", "Hip-Hop", "Metal", "Pop", "Rock")) %>% 
#   ggplot(aes(fiveyears, freq, colour = genre)) +
#   # geom_line() +
#   geom_smooth(se = FALSE) +
#   labs(x = "year", y = "smoothed")+
#   scale_y_continuous(labels = scales::percent_format()) 
```

# Data preparation

Tokenization for analysis
```{r}
songdata_words <- songdata %>%
  unnest_tokens(output = "word", input = "text", token = "words")
```

Most common words per genre
```{r}
songdata_words %>%
  count(genre, word) %>%
  top_n(10, n)
  
```



Remove stop words
```{r}
# custom_stopwords <- stop_words %>%
#   rbind(data.frame(word    = c("1", "na", "uh", "ooh", "an"),
#                    lexicon = rep("custom", 5)))
# 
# songdata_words <- songdata_words %>%
#   anti_join(custom_stopwords, by = "word")
# Think about if adding custom stop words
```

Stopwords
```{r}
stopwords <- lapply(stopwords_getsources()[stopwords_getsources() != "misc"], 
                    function(x) stopwords::stopwords(language = "en", source = x)) %>%
  unlist()
```

# Find best number of topics

Perplexity for hold-out set
```{r}
# Train DTM
set.seed(4324663) 
sampling <- sample(1:nrow(songdata), replace = FALSE,size = nrow(songdata)*0.7)
train_data <- songdata[sampling,]
DTM_train <- train_data %>%
  corpus() %>%
  tokens(what = "word",
         remove_numbers = TRUE, remove_punct = TRUE,
         remove_symbols = TRUE, remove_separators = TRUE)
docnames(DTM_train) <- paste(train_data$artist, train_data$song, sep = ";")
DTM_train <- DTM_train %>%
  dfm(tolower = TRUE, stem = TRUE, remove = stopwords) %>%
  convert(to = "tm")

# Test DTM
test_data <- songdata[-sampling,]
DTM_test <- test_data %>%
  corpus() %>%
  tokens(what = "word",
         remove_numbers = TRUE, remove_punct = TRUE,
         remove_symbols = TRUE, remove_separators = TRUE)
docnames(DTM_test) <- paste(test_data$artist, test_data$song, sep = ";")
DTM_test <- DTM_test %>%
  dfm(tolower = TRUE, stem = TRUE, remove = stopwords) %>%
  convert(to = "tm")

rm("sampling")

# Up to 20
perplexity_df <- data.frame(topics = numeric(), train = numeric(), test = numeric())
topics <- c(2:20)

# set.seed(4324663)
for (i in topics) {
  cat(paste(i, "topics..."))
  fitted <- LDA(DTM_train, k = i, method = "VEM",
                control = list(seed = 4324663))
  perplexity_df[i-1,1]  <- i
  perplexity_df[i-1,2]  <- perplexity(fitted, newdata = DTM_train)
  perplexity_df[i-1,3]  <- perplexity(fitted, newdata = DTM_test)
  cat(paste("done", "\n"))
}

perplexity_df %>%
  gather(key = "set", value = "perplexity", train, test) %>%
  ggplot() +
  geom_line(aes(x = topics, y = perplexity, color = set)) +
  scale_x_continuous(breaks = perplexity_df$topics) +
  scale_color_manual(values=c("#E69F00", "#56B4E9")) +
  labs(x = "number of topics")

perplexity_df %>%
  filter(topics %in% seq(2, 5))

rm("DTM_test", "DTM_train", "fitted", "test_data", "train_data", "i", "topics")
```

Transform all dataset into DocumentTermMatrix
```{r}
# songdata_dtm <- songdata_words %>%
#   count(artist, song, word, sort = TRUE) %>%
#   ungroup() %>%
#   cast_dtm(term = "word", document = "song", value = "n")

songdata_tokens <- songdata %>%
  corpus() %>%
  tokens(what = "word",
         remove_numbers = TRUE, remove_punct = TRUE,
         remove_symbols = TRUE, remove_separators = TRUE)

docnames(songdata_tokens) <- paste(songdata$artist, songdata$song, sep = ";")

songdata_dtm <- songdata_tokens %>%
  dfm(tolower = TRUE, stem = TRUE, remove = stopwords) %>%
  convert(to = "tm")

rm("songdata_tokens", "stopwords")
```

Rest of metrics
```{r}
# Up to 20
topic_numbers <- FindTopicsNumber(dtm     = songdata_dtm,
                                  topics  = seq(2, 20, by = 1),
                                  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
                                  method  = "VEM",
                                  control = list(seed = 4324663),
                                  verbose = TRUE)

# FindTopicsNumber_plot(topic_numbers)
topic_numbers %>%
  mutate_if(!grepl("topics", names(.)), function(x) 
                            scales::rescale(x, to = c(0, 1), from = range(x, na.rm = TRUE, finite = TRUE))) %>%
  gather(key = "metric", value = "value", CaoJuan2009, Arun2010, Deveaud2014) %>%
  mutate(optimization = ifelse(metric %in% c("CaoJuan2009", "Arun2010"), "minimize", "maximize")) %>%
  ggplot(aes(x = topics, y = value, color = metric)) +
  geom_line(stat = "identity") +
  geom_point(aes(shape = metric), size = 3) +
  scale_x_continuous(breaks = topic_numbers$topics) +
  labs(x = "number of topics", y = NULL) +
  facet_grid(optimization ~ .)

# Optimal values
topic_numbers %>%
  mutate(Deveaud2014 = ifelse(is.infinite(Deveaud2014), NA, Deveaud2014)) %>%
  mutate(CaoJuan2009min = min(CaoJuan2009),
         Arun2010min    = min(Arun2010),
         Deveaud2014max = max(Deveaud2014, na.rm = TRUE)) %>%
  filter(CaoJuan2009 == CaoJuan2009min |
         Arun2010    == Arun2010min |
         Deveaud2014 == Deveaud2014max)

# Up to 200 (all observations)
topic_numbers_all <- FindTopicsNumber(dtm     = songdata_dtm,
                                      topics  = seq(2, ndoc(songdata_dtm), by = 1),
                                      metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
                                      method  = "VEM",
                                      control = list(seed = 4324663),
                                      verbose = TRUE)


save.image(file = "topicsnumber.RData")

# FindTopicsNumber_plot(topic_numbers)
topic_numbers_all %>%
  # mutate(Deveaud2014 = ifelse(is.infinite(Deveaud2014), NA, Deveaud2014)) %>%
  mutate_if(!grepl("topics", names(.)),
            function(x) scales::rescale(x, to = c(0, 1), from = range(x, na.rm = TRUE, finite = TRUE))) %>%
  gather(key = "metric", value = "value", CaoJuan2009, Arun2010, Deveaud2014) %>%
  mutate(optimization = ifelse(metric %in% c("CaoJuan2009", "Arun2010"), "minimize", "maximize")) %>%
  ggplot(aes(x = topics, y = value, color = metric)) +
  geom_line(stat = "identity") +
  geom_point(aes(shape = metric), size = 1) +
  scale_x_continuous(breaks = seq(0, max(topic_numbers_all$topics), by = 10)) +
  guides(color = FALSE, shape = FALSE) +
  labs(x = "number of topics", y = NULL) +
  facet_grid(optimization ~ .)

topic_numbers_all <- topic_numbers_all %>%
  mutate(Deveaud2014na = ifelse(is.infinite(Deveaud2014), NA, Deveaud2014))

# data.frame(
#   metric = c("CaoJuan2009", "Arun2010", "Deveaud2014"),
#   value  = c(topic_numbers_all[topic_numbers_all$CaoJuan2009 == min(topic_numbers_all$CaoJuan2009),
#                                names(topic_numbers_all == "CaoJuan2009")],
#              topic_numbers_all[topic_numbers_all$Arun2010 == min(topic_numbers_all$Arun2010),
#                                names(topic_numbers_all == "Arun2010")],
#              topic_numbers_all[topic_numbers_all$Deveaud2014 == max(topic_numbers_all$Deveaud2014na, na.rm = TRUE),
#                                names(topic_numbers_all == "Deveaud2014na")]),
#   topics = c(topic_numbers_all[topic_numbers_all$CaoJuan2009 == min(topic_numbers_all$CaoJuan2009),
#                                names(topic_numbers_all == "topics")],
#              topic_numbers_all[topic_numbers_all$Arun2010 == min(topic_numbers_all$Arun2010),
#                                names(topic_numbers_all == "topics")],
#              topic_numbers_all[topic_numbers_all$Deveaud2014 == max(topic_numbers_all$Deveaud2014na, na.rm = TRUE),
#                                names(topic_numbers_all == "topics")]))

topic_numbers_all %>%
  mutate(Deveaud2014 = ifelse(is.infinite(Deveaud2014), NA, Deveaud2014)) %>%
  mutate(CaoJuan2009min = min(CaoJuan2009),
         Arun2010min    = min(Arun2010),
         Deveaud2014max = max(Deveaud2014, na.rm = TRUE)) %>%
  filter(CaoJuan2009 == CaoJuan2009min |
         Arun2010 == Arun2010min |
         Deveaud2014 == Deveaud2014max)

# rm("topic_numbers", "topic_numbers")

```

LDA with values of k from 2 to 5

```{r}
songdata_lda <- list()

for (k in 2:5) {
  
  cat(paste("LDA with k =", k, "..."))
  
  songdata_lda[[k]] <- LDA(songdata_dtm, k = k, method = "VEM", control = list(seed = 978324))
  
  cat("done\n")
  
}

rm(k)

save.image(file = "lda_25k.RData")
```

Calculate probabilites of interest:
- beta = per-topic-per-word probabilities
- lambda = per-document-per-topic probabilities
```{r}
# beta
songdata_beta <- list()
for (k in 2:length(songdata_lda)) {
  songdata_beta[[k]] <- tidy(songdata_lda[[k]], matrix = "beta")
}

# gamma
songdata_gamma <- list()
for (k in 2:length(songdata_lda)) {
  songdata_gamma[[k]] <- tidy(songdata_lda[[k]], matrix = "gamma")
}
```

Words in topics
```{r}
for (k in 2:length(songdata_beta)) {
  plot <- songdata_beta[[k]] %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>%
    mutate(term  = reorder(term, topic),
           topic = paste0("topic", topic)) %>%
    ggplot(aes(reorder(term, beta), beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    labs(x = "terms") +
    facet_wrap(~ topic, scales = "free_y") +
    theme(axis.title.x = element_blank()) +
    coord_flip()
  
  print(plot)
}

rm(plot)
```

Gamma for genres (= documents)
```{r}
genre_gamma <- songdata_gamma %>%
  separate(document, into = c("artist", "song"), sep = ";") %>%
  inner_join(songdata, by = c("artist", "song")) %>%
  dplyr::select(-year, -text)

genre_gamma %>%
  mutate(genre = reorder(genre, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma, colour = factor(topic))) +
  geom_boxplot(alpha = 0.7) +
  labs(y = "Probability", x = "Topic", 
       title = "Topic probabilities per music genre", 
       subtitle = "") +
  labs(col="Topics",
       y = "Probabilities") +
  facet_wrap(~ genre)


genre_gamma %>%
  mutate(genre = reorder(genre, gamma * topic)) %>%
  ggplot(aes(x = gamma, colour = factor(topic))) +
  geom_line(stat = "count") +
  labs(y = "Probability", x = "Topic", 
       title = "Topic probabilities per music genre", 
       subtitle = "") +
  labs(col="Topics",
       y = "Probabilities") +
  facet_wrap(~genre)
```